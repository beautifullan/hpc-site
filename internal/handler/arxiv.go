package handler

import (
	"fmt"
	"github.com/gin-gonic/gin"
	"hpc-site/internal/models"
	"hpc-site/internal/repository"
	"io"
	"log"
	"net/http"
	"regexp"
	"strconv"
	"strings"
	"time"

	_ "github.com/lib/pq"
)

const SearchPattern = "https://arxiv.org/search/?query=%s&searchtype=all&abstracts=hide&order=-announced_date_first&size=50&start=%d"
const SearchPageSize = 50 // arXiv æœç´¢é¡µé¢é»˜è®¤æ¯é¡µæ˜¾ç¤º 50 æ¡

func FetchArxivSearchHtml(softwareName string, start int) (string, error) {
	url := fmt.Sprintf(SearchPattern, softwareName, start)
	for i := 0; i < 3; i++ { // æœ€å¤šé‡è¯•ä¸‰æ¬¡
		resp, err := http.Get(url)
		defer resp.Body.Close() //::TODO åœ¨å¾ªç¯ä¸­è°ƒç”¨ defer æœ‰å¯èƒ½å¯¼è‡´èµ„æºæ³„æ¼
		if err != nil {
			log.Printf("âš ï¸ ç¬¬ %d æ¬¡è¯·æ±‚å¤±è´¥: %v", i+1, err)
			time.Sleep(2 * time.Second)
			continue
		}

		if resp.StatusCode == http.StatusOK {
			body, _ := io.ReadAll(resp.Body)
			return string(body), nil
		}
		log.Printf("âš ï¸ è¿”å›çŠ¶æ€ç  %dï¼Œé‡è¯•ä¸­...", resp.StatusCode)
		time.Sleep(2 * time.Second)
	}
	return "", fmt.Errorf("è¿ç»­è¯·æ±‚å¤±è´¥: %s", url)
}

func GetArxivIDsFromSearchHtml(html string) []string {
	// æ›´å®½æ¾çš„åŒ¹é…
	liRe := regexp.MustCompile(`(?s)<li[^>]*class="[^"]*arxiv-result[^"]*"[^>]*>(.*?)</li>`)
	blocks := liRe.FindAllStringSubmatch(html, -1)

	idRe := regexp.MustCompile(`https://arxiv\.org/abs/(\d{4}\.\d{4,5})`)
	seen := make(map[string]bool)
	ids := make([]string, 0)

	for _, block := range blocks {
		section := block[1]
		m := idRe.FindStringSubmatch(section)
		if len(m) > 1 {
			id := m[1]
			if !seen[id] {
				seen[id] = true
				ids = append(ids, id)
			}
		}
	}
	return ids
}

// æå–æ€»çš„ç»“æœæ•°é‡ï¼Œç”¨äºåˆ†é¡µç»ˆæ­¢å¤„ç†
func MatchTotalResults(html string) int {
	re := regexp.MustCompile(`of\s+([0-9,]+)\s+results`)
	match := re.FindStringSubmatch(html) //htmlä¸­ç¬¬ä¸€ä¸ªç¬¦åˆæ­£åˆ™çš„éƒ¨åˆ†
	if len(match) > 1 {
		// ç§»é™¤é€—å·ï¼Œå¹¶å°è¯•è½¬æ¢æˆæ•´æ•°
		totalStr := strings.ReplaceAll(match[1], ",", "")
		total, err := strconv.Atoi(totalStr)
		if err != nil {
			log.Printf("Error converting total results string '%s' to int: %v", totalStr, err)
			return 0
		}
		return total
	}
	return 0
}

func CrawlArxivAll(softwareName string) []string {
	start := 0
	page := 1
	allIDs := make(map[string]bool)
	total := 0

	for {
		log.Printf("ç¬¬ %d é¡µ start=%d", page, start)
		html, err := FetchArxivSearchHtml(softwareName, start)
		if err != nil {
			log.Printf("è·å–å¤±è´¥: %v", err)
			break
		}

		if total == 0 {
			total = MatchTotalResults(html)
			log.Printf("ğŸ“¦ æ€»å…± %d æ¡ç»“æœ", total)
			if total == 0 {
				break
			}
		}

		ids := GetArxivIDsFromSearchHtml(html)
		log.Printf("ç¬¬ %d é¡µè§£æå‡º %d æ¡", page, len(ids))
		for _, id := range ids {
			allIDs[id] = true
		}

		// æ£€æŸ¥æ˜¯å¦å·²åˆ°æœ«é¡µ
		if len(ids) == 0 || start+SearchPageSize >= total {
			log.Printf("æŠ“å–ç»“æŸ: å…± %d å”¯ä¸€è®ºæ–‡", len(allIDs))
			break
		}

		start += SearchPageSize
		page++
		time.Sleep(2 * time.Second)
	}

	// è½¬æˆ slice
	result := make([]string, 0, len(allIDs))
	for id := range allIDs {
		result = append(result, id)
	}
	return result
}

// loop to get all papers by paper-id
func GetArxivPageSource(id string, isWithDrawn bool, version int) string {
	url := FormatPageUrl(id, isWithDrawn, version)
	fmt.Println(url)
	resp, err := http.Get(url)
	if err != nil {
		log.Printf("Error fetching data: %v", err)
		return ""
	}
	defer resp.Body.Close()

	// æ£€æŸ¥å“åº”çŠ¶æ€
	if resp.StatusCode != http.StatusOK {
		log.Printf("Error: received status code %d", resp.StatusCode)
		return ""
	}

	// è¯»å–å“åº”ä½“
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		log.Printf("Error reading response body: %v", err)
		return ""
	}
	return string(body)
}

// è¯¦æƒ…é¡µçš„
func FormatPageUrl(id string, isWithDrawn bool, version int) string {
	if isWithDrawn {
		return fmt.Sprintf("https://arxiv.org/abs/%sv%d", id, version)
	} else {
		return fmt.Sprintf("https://arxiv.org/abs/%s", id)
	}
}

func GetPaperFromMetaData(extractedId string, software string) models.Paper {
	sourceCode := GetArxivPageSource(extractedId, false, 0)
	isLatestVersionWithDrawn := IsWithDrawn(sourceCode)
	title := MatchTitle(sourceCode)
	authors := MatchAuthors(sourceCode)
	abstract := MatchAbstract(sourceCode)
	if isLatestVersionWithDrawn {
		version := FindLastValidVersion(sourceCode)
		url := FormatPageUrl(extractedId, true, version)
		code := GetArxivPageSource(extractedId, true, version)
		log.Println("try to find latest valid version")
		pdf := MatchPdf(code)
		publishedTime := MatchSubmissionDate(code, isLatestVersionWithDrawn, version)
		return models.Paper{
			ID:            extractedId,
			Title:         title,
			Authors:       authors,
			Abstract:      abstract,
			URL:           url,
			Pdf:           pdf,
			PublishedTime: publishedTime,
			SoftwareNames: []string{software},
		}
	} else {
		url := fmt.Sprintf("https://arxiv.org/abs/%s", extractedId)
		log.Println("source code get,start to match content")
		pdf := MatchPdf(sourceCode)
		publishedTime := MatchSubmissionDate(sourceCode, false, 0)
		return models.Paper{
			ID:            extractedId,
			Title:         title,
			Authors:       authors,
			Abstract:      abstract,
			URL:           url,
			Pdf:           pdf,
			PublishedTime: publishedTime,
			SoftwareNames: []string{software}, // âœ… ä¸€æ ·è¦åŠ 
		}
	}
}

func IsWithDrawn(source string) bool {
	return strings.Contains(source, "This paper has been withdrawn by")
}

func MatchTitle(source string) string {
	regex := `(?s)<meta property="og:title" content="(.*?)"\s*\/>`
	return MatchContent(source, regex)
}

func MatchAuthors(source string) []string {
	regex := `<div class="authors"><span class="descriptor">Authors:<\/span>(.*?)<\/div>`
	authorListContent := MatchContent(source, regex)
	if authorListContent == "" {
		return []string{}
	}
	//æ‹†åˆ†æ¯ä¸ªä½œè€…éƒ¨åˆ†
	authorNameList := strings.Split(authorListContent, ",")
	authors := make([]string, 0, len(authorNameList))
	namePattern := `>(.*?)<`
	for _, authorItem := range authorNameList {
		author := MatchContent(authorItem, namePattern)
		if author != "" {
			authors = append(authors, author)
		}
	}
	return authors
}

func MatchAbstract(source string) string {
	regex := `(?s)<meta property="og:description" content="(.*?)"\/>`
	return MatchContent(source, regex)
}

func FindLastValidVersion(source string) int {
	regex := `(?s)<h2>Submission history<\/h2>(.*?)<\/div>`
	submissionSection := MatchContent(source, regex)
	submissionList := strings.Split(submissionSection, "</strong>")
	result := 0
	for index, line := range submissionList {
		if strings.Contains(line, "<a href") {
			result = index + 1
		}
	}
	return result
}

func MatchPdf(source string) string {
	regex := `<a\s*href="(.*)?"\s*aria-describedby="download-button-info" accesskey="f" class="abs-button download-pdf">View PDF<\/a>`
	fmt.Println(MatchContent(source, regex))
	return fmt.Sprintf("https://arxiv.org%s", MatchContent(source, regex))
}

func MatchSubmissionDate(source string, isWithDrawn bool, version int) string {
	regex := `(?s)<h2>Submission history<\/h2>(.*?)<\/div>`
	submissionSection := MatchContent(source, regex)
	submissionList := strings.Split(submissionSection, "</strong>")
	submissionArray := make([]string, 0)
	for _, item := range submissionList {
		if strings.Contains(item, "UTC") {
			submissionArray = append(submissionArray, item)
		}
	}
	if !isWithDrawn {
		matchedTime := strings.TrimSpace(MatchContent(submissionArray[len(submissionArray)-1], `(.*?UTC)`))
		return matchedTime
	} else {
		matchedTime := strings.TrimSpace(MatchContent(submissionArray[version-1], `(.*?UTC)`))
		return matchedTime
	}
}

func MatchContent(source string, regex string) string {
	re := regexp.MustCompile(regex)

	matches := re.FindStringSubmatch(source)
	// æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…é¡¹
	if len(matches) > 1 {
		// matches[0] æ˜¯å®Œæ•´çš„åŒ¹é…ï¼Œmatches[1] æ˜¯ç¬¬ä¸€ä¸ªæ•è·ç»„
		return matches[1]
	} else {
		return ""
	}
}

// æ•°æ®å†™å…¥

// splitAuthors æŠŠ "Alice; Bob" -> []string{"Alice","Bob"}
func splitAuthors(raw string) []string {
	if strings.TrimSpace(raw) == "" {
		return []string{}
	}
	parts := strings.Split(raw, ";")
	out := make([]string, 0, len(parts))
	for _, p := range parts {
		s := strings.TrimSpace(p)
		if s != "" {
			out = append(out, s)
		}
	}
	return out
}

func ProcessSoftwarePapers(softwareName string) {
	paperIds := CrawlArxivAll(softwareName)
	//åªæœ‰paperä¸å­˜åœ¨çš„æƒ…å†µæ‰éœ€è¦å»æŠ“
	log.Printf("å¼€å§‹æŠ“å–ä¸è½¯ä»¶ [%s] ç›¸å…³çš„è®ºæ–‡", softwareName)
	for i, paperId := range paperIds {
		log.Printf("[%d/%d] æ£€æŸ¥è®ºæ–‡ %s æ˜¯å¦å­˜åœ¨", i+1, len(paperIds), paperId)
		//åˆ¤æ–­æ˜¯å¦å­˜åœ¨
		exists, existingSoftwares, err := repository.CheckPaperExists(paperId)
		if err != nil {
			log.Printf("æ£€æŸ¥è®ºæ–‡ %s æ˜¯å¦å­˜åœ¨æ—¶å‡ºé”™: %v", paperId, err)
			continue
		}
		//å­˜åœ¨åˆ™åªæ›´æ–°software
		if exists {
			merged := repository.MergeUnique(existingSoftwares, []string{softwareName})
			if len(merged) != len(existingSoftwares) {
				log.Printf("è®ºæ–‡ %s å·²å­˜åœ¨ï¼Œåˆå¹¶è½¯ä»¶ [%s]", paperId, softwareName)
				err := repository.UpdatePaperSoftware(paperId, merged)
				if err != nil {
					log.Printf("æ›´æ–°è®ºæ–‡ %s è½¯ä»¶å¤±è´¥: %v", paperId, err)
				} else {
					log.Printf("å·²ä¸ºè®ºæ–‡ %s æ·»åŠ æ–°è½¯ä»¶ [%s]", paperId, softwareName)
				}
			} else {
				log.Printf("è®ºæ–‡ä¸è½¯ä»¶å·²ç»å­˜åœ¨ï¼Œæ— éœ€æ›´æ–°")
				continue
			}
		} else {
			//paperä¸å­˜åœ¨å°±å»æŠ“è¯¦æƒ…é¡µ
			paper := GetPaperFromMetaData(paperId, softwareName)
			if paper.ID == "" || paper.Title == "" {
				log.Printf("è®ºæ–‡ %s æŠ“å–å¤±è´¥ï¼Œè·³è¿‡", paperId)
				continue
			}
			err = repository.InsertNewPaper(paper)
			if err != nil {
				if err != nil {
					log.Printf("æ’å…¥è®ºæ–‡ %s å¤±è´¥: %v", paperId, err)
				} else {
					log.Printf("âœ… æˆåŠŸæ’å…¥è®ºæ–‡ %s", paperId)
				}
			}
		}
	}
	log.Printf("[%s] æŠ“å–å®Œæˆ", softwareName)

}

func TestLammps(c *gin.Context) {
	ProcessSoftwarePapers("Lammps")
	c.JSON(http.StatusOK, gin.H{
		"message": "test",
	})
}
